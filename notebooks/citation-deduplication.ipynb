{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ingest citation data via uploaded RIS or BibTex files or via manually-entered, individual records\n",
    "1. Parse citation data according to input format and standardize (across formats) field names and values as much as possible\n",
    "1. Munge parsed data into a convenient format for importing into a database, e.g. CSV -> Postgres (see [here](https://www.postgresql.org/docs/9.5/static/sql-copy.html))\n",
    "1. Import citations into database with additional columns for, e.g. citation_id, project_id, user_id, is_duplicate (NULL to start), confirmed_duplicate, ...\n",
    "1. Apply trained dedupe model to new citations vs. existing citations for given project, find possible matches, interactively prompt user to confirm duplicates when in doubt; mark duplicate records in the db accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from psycopg2 import connect as psql_connect\n",
    "from psycopg2 import Error as PsycopgError\n",
    "\n",
    "\n",
    "def get_connection(host, database, port=5439, username=None, password=None):\n",
    "    \"\"\"\n",
    "    Get PostgresSQL connection.\n",
    "    \n",
    "    @param host: str\n",
    "    @param database: str, name of the database.\n",
    "    @param port: int\n",
    "    @param username: str\n",
    "    @param password: str\n",
    "    @return: psycopg2._psycopg.connection|None\n",
    "    \"\"\"\n",
    "    connection_params = {\n",
    "        'host': host,\n",
    "        'port': port,\n",
    "        'user': username,\n",
    "        'password': password,\n",
    "        'database': database,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        connection = psql_connect(**connection_params)\n",
    "        logging.info('Connected to Redshift, %s:%s/%s', host, port, database)\n",
    "        return connection\n",
    "    except PsycopgError:\n",
    "        logging.exception('Failed to connect to redshift %s:%s/%s', host, port, database)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : el valor - carlos cantu\n",
      "Address : 2434 s kildare ave\n",
      "Zip : None\n",
      "Phone : None\n",
      "\n",
      "Site name : el valor - carlos cantu\n",
      "Address : 2434 s kildare ave\n",
      "Zip : None\n",
      "Phone : None\n",
      "\n",
      "0/10 positive, 0/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting active labeling...\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : pathways to learning i/t\n",
      "Address : 3450-54 w. 79th st\n",
      "Zip : None\n",
      "Phone : 4369244\n",
      "\n",
      "Site name : el valor - kidz colony\n",
      "Address : 6287 s archer ave\n",
      "Zip : None\n",
      "Phone : 7678522\n",
      "\n",
      "1/10 positive, 0/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : ferguson cpc\n",
      "Address : 1420 n. hudson\n",
      "Zip : None\n",
      "Phone : 5348580\n",
      "\n",
      "Site name : henry booth house precious little ones\n",
      "Address : 5327 s michigan ave\n",
      "Zip : 60615\n",
      "Phone : None\n",
      "\n",
      "1/10 positive, 1/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burtondewilde/.pyenv/versions/3.5.1/lib/python3.5/site-packages/rlr/crossvalidation.py:122: RuntimeWarning: invalid value encountered in true_divide\n",
      "  * (true_distinct + false_distinct)))\n",
      "Site name : community learning center, inc.\n",
      "Address : 10612-20 south wentworth\n",
      "Zip : 60628\n",
      "Phone : 9284104\n",
      "\n",
      "Site name : community learning center\n",
      "Address : 10612 s wentworth avenue\n",
      "Zip : 60628\n",
      "Phone : 9284104\n",
      "\n",
      "1/10 positive, 2/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : chicago public schools new field primary school\n",
      "Address : 1707 w. morse\n",
      "Zip : 60626\n",
      "Phone : 5342760\n",
      "\n",
      "Site name : healy\n",
      "Address : 3040 s. parnell\n",
      "Zip : 60616\n",
      "Phone : 5349170\n",
      "\n",
      "2/10 positive, 2/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : easter seals society of metropolitan chicago allison's infant & toddler center\n",
      "Address : 234 e 114th st\n",
      "Zip : 60628\n",
      "Phone : 8404502\n",
      "\n",
      "Site name : henry booth house allison's\n",
      "Address : 34 e. 115th st.\n",
      "Zip : 60628\n",
      "Phone : 8404502\n",
      "\n",
      "2/10 positive, 3/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : catholic charities-st mark\n",
      "Address : 1041 n. campbell\n",
      "Zip : 60622\n",
      "Phone : 7726606\n",
      "\n",
      "Site name : catholic charities chicago - st. mark\n",
      "Address : 1041 n campbell avenue\n",
      "Zip : 60622\n",
      "Phone : 7726606\n",
      "\n",
      "2/10 positive, 4/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : national teachers acad\n",
      "Address : 55 w. cermack\n",
      "Zip : None\n",
      "Phone : 5349970\n",
      "\n",
      "Site name : chicago public schools n.t.a. (national teachers academy)\n",
      "Address : 55 w. cermak\n",
      "Zip : 60616\n",
      "Phone : 5349970\n",
      "\n",
      "3/10 positive, 4/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : henry booth house - little hands & feet\n",
      "Address : 7801 s wolcott ave\n",
      "Zip : None\n",
      "Phone : None\n",
      "\n",
      "Site name : evers\n",
      "Address : 9811 s. lowe\n",
      "Zip : None\n",
      "Phone : 5352565\n",
      "\n",
      "4/10 positive, 4/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : beethoven\n",
      "Address : 25 w. 47th st.\n",
      "Zip : None\n",
      "Phone : 5351480\n",
      "\n",
      "Site name : beethoven\n",
      "Address : 4421 s. state st.\n",
      "Zip : 60609\n",
      "Phone : 5351480\n",
      "\n",
      "4/10 positive, 5/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : chicago youth centers - rebecca k. crown / cyc\n",
      "Address : 7601 s phillips ave\n",
      "Zip : None\n",
      "Phone : 6481550\n",
      "\n",
      "Site name : chicago youth centers rebecca crown\n",
      "Address : 7601 s. phillips\n",
      "Zip : 60649\n",
      "Phone : 7310444\n",
      "\n",
      "4/10 positive, 5/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : dumas\n",
      "Address : 6615 s. kenwood ave\n",
      "Zip : None\n",
      "Phone : 5350802\n",
      "\n",
      "Site name : dumas\n",
      "Address : 6650 s. ellis\n",
      "Zip : 60637\n",
      "Phone : 5350750\n",
      "\n",
      "4/10 positive, 5/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : kiddy kare preschools little learners\n",
      "Address : 5923 w. 63rd st.\n",
      "Zip : None\n",
      "Phone : 5815541\n",
      "\n",
      "Site name : el valor - little learners\n",
      "Address : 5923 w 63rd st\n",
      "Zip : None\n",
      "Phone : 5815541\n",
      "\n",
      "4/10 positive, 6/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : viva family center\n",
      "Address : 2516 w. division\n",
      "Zip : 60622\n",
      "Phone : 2529100\n",
      "\n",
      "Site name : children's home viva family center\n",
      "Address : 2516 w. division\n",
      "Zip : 60602\n",
      "Phone : 2526313\n",
      "\n",
      "5/10 positive, 6/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Site name : douglass-tubman youth ministries,inc. - douglass-tubman child development center\n",
      "Address : 5010 w chicago ave\n",
      "Zip : None\n",
      "Phone : 6266581\n",
      "\n",
      "Site name : douglas-tubman child development center\n",
      "Address : 5010 w chicago avenue\n",
      "Zip : 60651\n",
      "Phone : 2683053\n",
      "\n",
      "6/10 positive, 6/10 negative\n",
      "Do these records refer to the same thing?\n",
      "(y)es / (n)o / (u)nsure / (f)inished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished labeling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burtondewilde/.pyenv/versions/3.5.1/lib/python3.5/site-packages/numpy/core/numeric.py:190: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  a = empty(shape, dtype, order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicate sets 849\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code demonstrates how to use dedupe with a comma separated values\n",
    "(CSV) file. All operations are performed in memory, so will run very\n",
    "quickly on datasets up to ~10,000 rows.\n",
    "\n",
    "We start with a CSV file containing our messy data. In this example,\n",
    "it is listings of early childhood education centers in Chicago\n",
    "compiled from several different sources.\n",
    "\n",
    "The output will be a CSV with our clustered results.\n",
    "\n",
    "For larger datasets, see our [mysql_example](mysql_example.html)\n",
    "\"\"\"\n",
    "from future.builtins import next\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import logging\n",
    "import optparse\n",
    "\n",
    "import dedupe\n",
    "from unidecode import unidecode\n",
    "\n",
    "# ## Logging\n",
    "\n",
    "log_level = logging.WARNING \n",
    "logging.getLogger().setLevel(log_level)\n",
    "\n",
    "# ## Setup\n",
    "\n",
    "input_file = '/Users/burtondewilde/Desktop/datakind/ci/conservation-intl/data/raw/csv_example_messy_input.csv'\n",
    "outputs_path = '/Users/burtondewilde/Desktop/datakind/ci/conservation-intl/data/processed'\n",
    "output_file = os.path.join(outputs_path, 'csv_example_output.csv')\n",
    "settings_file = os.path.join(outputs_path, 'csv_example_learned_settings')\n",
    "training_file = os.path.join(outputs_path, 'csv_example_training.json')\n",
    "\n",
    "\n",
    "def preProcess(column):\n",
    "    \"\"\"\n",
    "    Do a little bit of data cleaning with the help of Unidecode and Regex.\n",
    "    Things like casing, extra spaces, quotes and new lines can be ignored.\n",
    "    \"\"\"\n",
    "    try : # python 2/3 string differences\n",
    "        column = column.decode('utf8')\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    column = unidecode(column)\n",
    "    column = re.sub('  +', ' ', column)\n",
    "    column = re.sub('\\n', ' ', column)\n",
    "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
    "    # If data is missing, indicate that by setting the value to `None`\n",
    "    if not column:\n",
    "        column = None\n",
    "    return column\n",
    "\n",
    "\n",
    "def readData(filename):\n",
    "    \"\"\"\n",
    "    Read in our data from a CSV file and create a dictionary of records, \n",
    "    where the key is a unique record ID and each value is dict\n",
    "    \"\"\"\n",
    "\n",
    "    data_d = {}\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            clean_row = [(k, preProcess(v)) for (k, v) in row.items()]\n",
    "            row_id = int(row['Id'])\n",
    "            data_d[row_id] = dict(clean_row)\n",
    "\n",
    "    return data_d\n",
    "\n",
    "print('importing data ...')\n",
    "data_d = readData(input_file)\n",
    "\n",
    "# If a settings file already exists, we'll just load that and skip training\n",
    "if os.path.exists(settings_file):\n",
    "    print('reading from', settings_file)\n",
    "    with open(settings_file, 'rb') as f:\n",
    "        deduper = dedupe.StaticDedupe(f)\n",
    "else:\n",
    "    # ## Training\n",
    "\n",
    "    # Define the fields dedupe will pay attention to\n",
    "    fields = [\n",
    "        {'field' : 'Site name', 'type': 'String'},\n",
    "        {'field' : 'Address', 'type': 'String'},\n",
    "        {'field' : 'Zip', 'type': 'Exact', 'has missing' : True},\n",
    "        {'field' : 'Phone', 'type': 'String', 'has missing' : True},\n",
    "        ]\n",
    "\n",
    "    # Create a new deduper object and pass our data model to it.\n",
    "    deduper = dedupe.Dedupe(fields)\n",
    "\n",
    "    # To train dedupe, we feed it a sample of records.\n",
    "    deduper.sample(data_d, 15000)\n",
    "\n",
    "    # If we have training data saved from a previous run of dedupe,\n",
    "    # look for it and load it in.\n",
    "    # __Note:__ if you want to train from scratch, delete the training_file\n",
    "    if os.path.exists(training_file):\n",
    "        print('reading labeled examples from ', training_file)\n",
    "        with open(training_file, 'rb') as f:\n",
    "            deduper.readTraining(f)\n",
    "\n",
    "    # ## Active learning\n",
    "    # Dedupe will find the next pair of records\n",
    "    # it is least certain about and ask you to label them as duplicates\n",
    "    # or not.\n",
    "    # use 'y', 'n' and 'u' keys to flag duplicates\n",
    "    # press 'f' when you are finished\n",
    "    print('starting active labeling...')\n",
    "\n",
    "    dedupe.consoleLabel(deduper)\n",
    "\n",
    "    # Using the examples we just labeled, train the deduper and learn\n",
    "    # blocking predicates\n",
    "    deduper.train()\n",
    "\n",
    "    # When finished, save our training to disk\n",
    "    with open(training_file, 'w') as tf:\n",
    "        deduper.writeTraining(tf)\n",
    "\n",
    "    # Save our weights and predicates to disk.  If the settings file\n",
    "    # exists, we will skip all the training and learning next time we run\n",
    "    # this file.\n",
    "    with open(settings_file, 'wb') as sf:\n",
    "        deduper.writeSettings(sf)\n",
    "        \n",
    "# Find the threshold that will maximize a weighted average of our\n",
    "# precision and recall.  When we set the recall weight to 2, we are\n",
    "# saying we care twice as much about recall as we do precision.\n",
    "#\n",
    "# If we had more data, we would not pass in all the blocked data into\n",
    "# this function but a representative sample.\n",
    "\n",
    "threshold = deduper.threshold(data_d, recall_weight=1)\n",
    "\n",
    "# ## Clustering\n",
    "\n",
    "# `match` will return sets of record IDs that dedupe\n",
    "# believes are all referring to the same entity.\n",
    "\n",
    "print('clustering...')\n",
    "clustered_dupes = deduper.match(data_d, threshold)\n",
    "\n",
    "print('# duplicate sets', len(clustered_dupes))\n",
    "\n",
    "# ## Writing Results\n",
    "\n",
    "# Write our original data back out to a CSV with a new column called \n",
    "# 'Cluster ID' which indicates which records refer to each other.\n",
    "\n",
    "cluster_membership = {}\n",
    "cluster_id = 0\n",
    "for (cluster_id, cluster) in enumerate(clustered_dupes):\n",
    "    id_set, scores = cluster\n",
    "    cluster_d = [data_d[c] for c in id_set]\n",
    "    canonical_rep = dedupe.canonicalize(cluster_d)\n",
    "    for record_id, score in zip(id_set, scores):\n",
    "        cluster_membership[record_id] = {\n",
    "            \"cluster id\" : cluster_id,\n",
    "            \"canonical representation\" : canonical_rep,\n",
    "            \"confidence\": score\n",
    "        }\n",
    "\n",
    "singleton_id = cluster_id + 1\n",
    "\n",
    "with open(output_file, 'w') as f_output, open(input_file) as f_input:\n",
    "    writer = csv.writer(f_output)\n",
    "    reader = csv.reader(f_input)\n",
    "\n",
    "    heading_row = next(reader)\n",
    "    heading_row.insert(0, 'confidence_score')\n",
    "    heading_row.insert(0, 'Cluster ID')\n",
    "    canonical_keys = canonical_rep.keys()\n",
    "    for key in canonical_keys:\n",
    "        heading_row.append('canonical_' + key)\n",
    "\n",
    "    writer.writerow(heading_row)\n",
    "\n",
    "    for row in reader:\n",
    "        row_id = int(row[0])\n",
    "        if row_id in cluster_membership:\n",
    "            cluster_id = cluster_membership[row_id][\"cluster id\"]\n",
    "            canonical_rep = cluster_membership[row_id][\"canonical representation\"]\n",
    "            row.insert(0, cluster_membership[row_id]['confidence'])\n",
    "            row.insert(0, cluster_id)\n",
    "            for key in canonical_keys:\n",
    "                row.append(canonical_rep[key].encode('utf8'))\n",
    "        else:\n",
    "            row.insert(0, None)\n",
    "            row.insert(0, singleton_id)\n",
    "            singleton_id += 1\n",
    "            for key in canonical_keys:\n",
    "                row.append(None)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4760381"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: get data into a suitable format\n",
    "\n",
    "# data = {unique_id_1: dict(record_1),\n",
    "#         unique_id_2: dict(record_2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variables = [\n",
    "    {'field': 'authors', 'type': 'Set', 'has missing': True},\n",
    "    {'field': 'title', 'type': 'String'},\n",
    "    {'field': 'abstract', 'type': 'Text'},\n",
    "    {'field': 'publication_year', 'type': 'Exact', 'has missing': True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deduper = dedupe.Dedupe(variables, num_cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_size = 15000\n",
    "deduper.sample(data, sample_size=sample_size, blocked_proportion=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use 'y', 'n' and 'u' keys to flag duplicates press 'f' when you are finished\n",
    "dedupe.consoleLabel(deduper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using the examples we just labeled, train the deduper and learn blocking predicates\n",
    "deduper.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
