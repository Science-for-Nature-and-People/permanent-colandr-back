{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "from collections import Counter\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from cipy import parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('cipy')\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/burtondewilde/Desktop/datakind/ci/conservation-intl/data/raw/citation_files/dedupe_tests/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scopus0.ris\n",
      "scopus1.ris"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:cipy.parsers.ris:duplicate key error: key=place_published, value=Perth, Aust\n",
      "ERROR:cipy.parsers.ris:duplicate key error: key=place_published, value=Washington, DC, USA\n",
      "ERROR:cipy.parsers.ris:duplicate key error: key=place_published, value=Nagoya, Jpn\n",
      "ERROR:cipy.parsers.ris:duplicate key error: key=place_published, value=Pittsburgh, PA, USA\n",
      "ERROR:cipy.parsers.ris:duplicate key error: key=place_published, value=Madison, WI, USA\n",
      "ERROR:cipy.parsers.ris:duplicate key error: key=place_published, value=Boston, MA, USA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "scopus2.ris\n",
      "scopus3.ris\n",
      "WoS0.txt\n",
      "Wos1.txt\n",
      "WoS2.txt\n",
      "WoS3.txt\n",
      "WoS4.txt\n",
      "WoS5.txt\n",
      "WoS6.txt\n",
      "WoS7.txt"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cipy.parsers.ris:unknown tag: tag=D2, line=9604 \"D2 10.1007/978-3-540-73349-2\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WoS8.txt\n"
     ]
    }
   ],
   "source": [
    "# RIS FORMAT\n",
    "\n",
    "unique_ris_keys = Counter()\n",
    "for fname in os.listdir(data_path):\n",
    "    if fname.endswith('.ris') or fname.endswith('.txt'):\n",
    "        print(fname)\n",
    "        ris = parsers.RisFile(os.path.join(data_path, fname))\n",
    "        unique_ris_keys.update(key\n",
    "                               for record in ris.parse()\n",
    "                               for key in record.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scopus0.bib\n",
      "scopus1.bib"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:cipy.parsers.bibtex:unusual \"pages\" field value: i-ii+S1-S266\n",
      "DEBUG:cipy.parsers.bibtex:unusual \"pages\" field value: b-141-64\n",
      "DEBUG:cipy.parsers.bibtex:unusual \"pages\" field value: 066133-1-066133-5\n",
      "DEBUG:cipy.parsers.bibtex:unusual \"pages\" field value: 181-190,193-199,203-241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "scopus2.bib\n",
      "scopus3.bib\n",
      "WoS0.bib\n",
      "WoS1.bib\n",
      "WoS2.bib\n",
      "WoS3.bib\n",
      "WoS4.bib\n",
      "WoS5.bib\n",
      "WoS6.bib\n",
      "WoS7.bib\n",
      "WoS8.bib\n"
     ]
    }
   ],
   "source": [
    "# BIBTEX FORMAT\n",
    "\n",
    "unique_bib_keys = Counter()\n",
    "for fname in os.listdir(data_path):\n",
    "    if fname.endswith('.bib'):\n",
    "        print(fname)\n",
    "        \n",
    "        bib = parsers.BibTexFile(os.path.join(data_path, fname))\n",
    "        unique_bib_keys.update(key\n",
    "                               for record in bib.parse()\n",
    "                               for key in record.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title....................     12010\n",
      "publication_year.........     12008\n",
      "issn.....................     12007\n",
      "authors..................     11984\n",
      "volume...................     11744\n",
      "abstract.................     11504\n",
      "end_page.................     11119\n",
      "doi......................     10602\n",
      "issue_number.............      8976\n",
      "language.................      8491\n",
      "name_of_database.........      8000\n",
      "notes....................      8000\n",
      "type_of_reference........      8000\n",
      "secondary_title..........      7999\n",
      "type_of_work.............      7965\n",
      "journal_name_user_abbr_2.      7891\n",
      "author_addresses.........      7796\n",
      "url......................      7713\n",
      "keywords.................      7441\n",
      "pages....................      7304\n",
      "publisher................      4025\n",
      "unique_identifier........      4010\n",
      "source_name..............      4010\n",
      "publication_type.........      4010\n",
      "start_page...............      3962\n",
      "publication_date.........      3719\n",
      "custom_2.................      2984\n",
      "pubmed_id................      2184\n",
      "reviewed_item............      1431\n",
      "open_researcher_contributor_id      1132\n",
      "custom_7.................       867\n",
      "electronic_intl_issn.....       703\n",
      "publisher_city...........       500\n",
      "document_delivery_number.       500\n",
      "num_cited_references.....       500\n",
      "document_type............       500\n",
      "num_times_cited..........       500\n",
      "user_defined_2...........       500\n",
      "subject_categories.......       500\n",
      "publisher_address........       500\n",
      "times_cited..............       500\n",
      "user_defined_1...........       500\n",
      "source_abbr_29char.......       500\n",
      "page_count...............       500\n",
      "subject_categories_alt...       500\n",
      "source_abbr_iso..........       498\n",
      "place_published..........       460\n",
      "reprint_status...........       459\n",
      "reference_id.............       456\n",
      "custom_1.................       440\n",
      "access_date..............       259\n",
      "custom_3.................       259\n",
      "author_keywords..........       204\n",
      "conference_location......       197\n",
      "title_of_unpublished_ref.       197\n",
      "email_address............       191\n",
      "caption..................       165\n",
      "article_number...........       162\n",
      "short_title..............        98\n",
      "subsidiary_authors.......        96\n",
      "special_issue............        51\n",
      "part_number..............        48\n",
      "supplement...............        38\n",
      "conference_host..........        35\n",
      "funding_agency_and_grants        32\n",
      "funding_text.............        32\n",
      "section..................        19\n",
      "isbn.....................        15\n",
      "secondary_authors........        10\n",
      "D2.......................         1\n"
     ]
    }
   ],
   "source": [
    "for key, count in unique_ris_keys.most_common():\n",
    "    print('{0:.<25} {1:>9}'.format(key, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID.......................     12010\n",
      "ENTRYTYPE................     12010\n",
      "title....................     12010\n",
      "publication_year.........     12008\n",
      "journal_name.............     12000\n",
      "authors..................     11985\n",
      "volume...................     11742\n",
      "issn.....................     11723\n",
      "abstract.................     11505\n",
      "pages....................     11141\n",
      "doi......................     10588\n",
      "issue_number.............      9040\n",
      "notes....................      8205\n",
      "source...................      8000\n",
      "link.....................      8000\n",
      "language.................      7991\n",
      "document_type............      7965\n",
      "abbrev_source_title......      7891\n",
      "affiliation..............      7796\n",
      "correspondence_address1..      7569\n",
      "references...............      7501\n",
      "keywords.................      5894\n",
      "coden....................      5286\n",
      "author_keywords..........      4654\n",
      "unique-id................      4010\n",
      "publication_month........      3733\n",
      "publisher................      3525\n",
      "pubmed_id................      2984\n",
      "chemicals_cas............      1979\n",
      "funding_details..........      1434\n",
      "researcherid-numbers.....      1408\n",
      "orcid-numbers............      1105\n",
      "art_number...............       867\n",
      "eissn....................       695\n",
      "isbn.....................       338\n",
      "publisher_address........       250\n",
      "tradenames...............       229\n",
      "article-number...........       168\n",
      "molecular_seqnumbers.....       131\n",
      "organization.............       126\n",
      "manufacturers............       118\n",
      "sponsors.................        93\n",
      "page_count...............        63\n",
      "series...................        17\n",
      "editor...................        16\n",
      "booktitle................         9\n",
      "book-group-author........         2\n"
     ]
    }
   ],
   "source": [
    "for key, count in unique_bib_keys.most_common():\n",
    "    print('{0:.<25} {1:>9}'.format(key, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RIS Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parse .RIS files from Scopus or Mendeley, as well as plaintext exports from\n",
    "Web of Science; return as a list of dictionaries, where each citation record\n",
    "is a dictionary whose keys are field names and values are field values.\n",
    "\"\"\"\n",
    "import io\n",
    "import re\n",
    "\n",
    "from dateutil.parser import parse as parse_date\n",
    "\n",
    "\n",
    "TAG_KEY_MAPPING = {\n",
    "    'A1': 'primary_authors',  # special: Lastname, Firstname, Suffix\n",
    "    'A2': 'secondary_authors',  # special: Lastname, Firstname, Suffix\n",
    "    'A3': 'tertiary_authors',  # special: Lastname, Firstname, Suffix\n",
    "    'A4': 'subsidiary_authors',  # special: Lastname, Firstname, Suffix\n",
    "    'AB': 'abstract',\n",
    "    'AD': 'author_address',\n",
    "    'AN': 'accession_number',\n",
    "    'AU': 'authors',  # special\n",
    "    'AV': 'location_in_archives',\n",
    "    'BN': 'isbn',\n",
    "    'BP': 'start_page',\n",
    "    'BT': 'bt',\n",
    "    'C1': 'custom_1',\n",
    "    'C2': 'custom_2',\n",
    "    'C3': 'custom_3',\n",
    "    'C4': 'custom_4',\n",
    "    'C5': 'custom_5',\n",
    "    'C6': 'custom_6',\n",
    "    'C7': 'custom_7',\n",
    "    'C8': 'custom_8',\n",
    "    'CA': 'caption',\n",
    "    'CN': 'call_number',\n",
    "    'CP': 'cp',\n",
    "    'CT': 'title_of_unpublished_ref',\n",
    "    'CY': 'place_published',\n",
    "    'DA': 'date',  # special: YYYY, YYYY/MM, YYYY/MM/DD/, or YYYY/MM/DD/other info\n",
    "    'DB': 'name_of_database',\n",
    "    'DE': 'author_keywords',\n",
    "    'DI': 'doi',\n",
    "    'DO': 'doi',\n",
    "    'DP': 'database_provider',\n",
    "    'DT': 'document_type',\n",
    "    'ED': 'editor',\n",
    "    'EF': 'end_file',  # ignore!\n",
    "    'EM': 'email_address',\n",
    "    'EP': 'end_page',\n",
    "    'ER': 'end_of_reference',  # special: must be empty and last tag of record\n",
    "    'ET': 'edition',\n",
    "    'FN': 'file_name',  # ignore!\n",
    "    'ID': 'reference_id',\n",
    "    'IS': 'issue_number',\n",
    "    'J1': 'journal_name_user_abbr_1',\n",
    "    'J2': 'journal_name_user_abbr_2',\n",
    "    'JA': 'journal_name_abbr',\n",
    "    'JF': 'journal_name',\n",
    "    'JO': 'journal_name',\n",
    "    'KW': 'keywords',  # special\n",
    "    'L1': 'link_to_pdf',\n",
    "    'L2': 'link_to_fulltext',\n",
    "    'L3': 'related_records',\n",
    "    'L4': 'figure',\n",
    "    'LA': 'language',\n",
    "    'LB': 'label',\n",
    "    'LK': 'link_to_website',\n",
    "    'M1': 'number',\n",
    "    'M2': 'miscellaneous_2',\n",
    "    'M3': 'type_of_work',\n",
    "    'N1': 'notes',\n",
    "    'N2': 'abstract',\n",
    "    'NV': 'number_of_volumes',\n",
    "    'OP': 'original_publication',\n",
    "    'PB': 'publisher',\n",
    "    'PD': 'publication_date',\n",
    "    'PP': 'publishing_place',\n",
    "    'PT': 'publication_type',\n",
    "    'PY': 'publication_year',  # special: YYYY\n",
    "    'RI': 'reviewed_item',\n",
    "    'RN': 'research_notes',\n",
    "    'RP': 'reprint_status',  # special: 'IN FILE', 'NOT IN FILE', or 'ON REQUEST (MM/DD/YY)'\n",
    "    'SE': 'section',\n",
    "    'SN': 'issn',\n",
    "    'SO': 'source_name',\n",
    "    'SP': 'start_page',\n",
    "    'ST': 'short_title',\n",
    "    'SU': 'supplement',\n",
    "    'T1': 'primary_title',\n",
    "    'T2': 'secondary_title',  # note: journal_title, if applicable\n",
    "    'T3': 'tertiary_title',\n",
    "    'TA': 'translated_author',\n",
    "    'TC': 'times_cited',\n",
    "    'TI': 'title',\n",
    "    'TT': 'translated_title',\n",
    "    'TY': 'type_of_reference',  # special: must be key in REFERENCE_TYPES and first tag of record\n",
    "    'U1': 'user_defined_1',\n",
    "    'U2': 'user_defined_2',\n",
    "    'U3': 'user_defined_3',\n",
    "    'U4': 'user_defined_4',\n",
    "    'U5': 'user_defined_5',\n",
    "    'UR': 'url',\n",
    "    'UT': 'unique_identifier',\n",
    "    'VL': 'volume',\n",
    "    'VO': 'published_standard_number',\n",
    "    'VR': 'version',  # ignore!\n",
    "    'Y1': 'primary_date',  # special: YYYY/\n",
    "    'Y2': 'access_date',\n",
    "}\n",
    "\n",
    "REFERENCE_TYPES_MAPPING = {\n",
    "    'ABST': 'abstract',\n",
    "    'ADVS': 'audiovisual material',\n",
    "    'AGGR': 'aggregated database',\n",
    "    'ANCIENT': 'ancient text',\n",
    "    'ART': 'art work',\n",
    "    'BILL': 'bill/resolution',\n",
    "    'BLOG': 'blog',\n",
    "    'BOOK': 'book',\n",
    "    'CASE': 'case',\n",
    "    'CHAP': 'book chapter',\n",
    "    'CHART': 'chart',\n",
    "    'CLSWK': 'classical cork',\n",
    "    'COMP': 'computer program',\n",
    "    'CONF': 'conference proceeding',\n",
    "    'CPAPER': 'conference paper',\n",
    "    'CTLG': 'catalog',\n",
    "    'DATA': 'data file',\n",
    "    'DBASE': 'online database',\n",
    "    'DICT': 'dictionary',\n",
    "    'EBOOK': 'electronic book',\n",
    "    'ECHAP': 'electronic book chapter',\n",
    "    'EDBOOK': 'edited book',\n",
    "    'EJOUR': 'electronic article',\n",
    "    'ELEC': 'web page',\n",
    "    'ENCYC': 'encyclopedia',\n",
    "    'EQUA': 'equation',\n",
    "    'FIGURE': 'figure',\n",
    "    'GEN': 'generic',\n",
    "    'GOVDOC': 'government document',\n",
    "    'GRANT': 'grant',\n",
    "    'HEAR': 'hearing',\n",
    "    'ICOMM': 'internet communication',\n",
    "    'INPR': 'in press',\n",
    "    'JFULL': 'journal (full)',\n",
    "    'JOUR': 'journal',\n",
    "    'LEGAL': 'legal rule or regulation',\n",
    "    'MANSCPT': 'manuscript',\n",
    "    'MAP': 'map',\n",
    "    'MGZN': 'magazine article',\n",
    "    'MPCT': 'motion picture',\n",
    "    'MULTI': 'online multimedia',\n",
    "    'MUSIC': 'music score',\n",
    "    'NEWS': 'newspaper',\n",
    "    'PAMP': 'pamphlet',\n",
    "    'PAT': 'patent',\n",
    "    'PCOMM': 'personal communication',\n",
    "    'RPRT': 'report',\n",
    "    'SER': 'serial publication',\n",
    "    'SLIDE': 'slide',\n",
    "    'SOUND': 'sound recording',\n",
    "    'STAND': 'standard',\n",
    "    'STAT': 'statute',\n",
    "    'THES': 'thesis/dissertation',\n",
    "    'UNBILL': 'unenacted bill/resolution',\n",
    "    'UNPB': 'unpublished work',\n",
    "    'VIDEO': 'video recording',\n",
    "}\n",
    "\n",
    "MULTI_TAGS = {'A1', 'A2', 'A3', 'A4', 'AD', 'AU', 'KW', 'N1'}\n",
    "IGNORE_TAGS = {'FN', 'VR', 'EF'}\n",
    "START_TAGS = {'TY', 'PT'}\n",
    "END_TAG = 'ER'\n",
    "\n",
    "# TAG_RE = re.compile(r'^([A-Z][A-Z0-9])(  - | )|^(E[FR])(\\s?$|  - | )')\n",
    "TAGv1_RE = re.compile(r'^(?P<tag>[A-Z][A-Z0-9])(  - )')\n",
    "TAGv2_RE = re.compile(r'^(?P<tag>[A-Z][A-Z0-9])( )|^(?P<endtag>E[FR])(\\s?$)')\n",
    "\n",
    "\n",
    "VALUE_SANITIZERS = {\n",
    "    'DA': lambda x: parse_date(x).strftime('%Y-%m-%d'),\n",
    "    'PY': lambda x: int(x),\n",
    "    'TC': lambda x: int(x),\n",
    "    'TY': lambda x: REFERENCE_TYPES_MAPPING.get(x, x),\n",
    "    'Y1': lambda x: parse_date('-'.join(item if item else '01' for item in x[:-1].split('/'))),\n",
    "    'Y2': lambda x: min(parse_date(val) for val in x.split(' through ')),\n",
    "    }\n",
    "\n",
    "\n",
    "def _add_tag_line(tag, line, start_idx, record):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tag (str)\n",
    "        line (str)\n",
    "        start_idx (int)\n",
    "        record (dict)\n",
    "    \"\"\"\n",
    "    key = TAG_KEY_MAPPING[tag]\n",
    "    value = line[start_idx:].strip()\n",
    "    # try to sanitize value, but don't sweat failure\n",
    "    try:\n",
    "        value = VALUE_SANITIZERS[tag](value)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    except Exception:\n",
    "        print('value sanitization error: key={}, value={}'.format(key, value))\n",
    "    # for multi-value tags, append to a list\n",
    "    if tag in MULTI_TAGS:\n",
    "        try:\n",
    "            record[key].append(value)\n",
    "        except KeyError:\n",
    "            record[key] = [value]\n",
    "    # otherwise, add key:value to record\n",
    "    else:\n",
    "        if key in record:\n",
    "            print('duplicate key error: key={}, value={}'.format(key, value))\n",
    "        record[key] = value\n",
    "\n",
    "\n",
    "def parse_ris_file(path):\n",
    "    with io.open(path, mode='r') as f:\n",
    "\n",
    "        in_record = False\n",
    "        tag_re = None\n",
    "        prev_tag = None\n",
    "        record = {}\n",
    "        records = []\n",
    "\n",
    "        for i, line in enumerate(f):\n",
    "\n",
    "            if not line.strip():\n",
    "                continue\n",
    "\n",
    "            # automatically detect regex needed for this RIS file\n",
    "            if tag_re is None:\n",
    "                tag_re = (TAGv1_RE if TAGv1_RE.match(line)\n",
    "                          else TAGv2_RE if TAGv2_RE.match(line)\n",
    "                          else None)\n",
    "                if tag_re is None:\n",
    "                    raise IOError('file {} is not formatted as expected!'.format(path))\n",
    "\n",
    "            tag_match = tag_re.match(line)\n",
    "            if tag_match:\n",
    "\n",
    "                tag = tag_match.group('tag') or tag_match.group('endtag')\n",
    "\n",
    "                if tag in IGNORE_TAGS:\n",
    "                    prev_tag = tag\n",
    "                    continue\n",
    "\n",
    "                elif tag == END_TAG:\n",
    "                    if in_record is False:\n",
    "                        msg = 'found end tag, but not in a record!\\nline: {} {}'.format(i, line.strip())\n",
    "                        raise IOError(msg)\n",
    "                    records.append(record)\n",
    "                    in_record = False\n",
    "                    record = {}\n",
    "                    prev_tag = tag\n",
    "                    continue\n",
    "\n",
    "                elif tag in START_TAGS:\n",
    "                    if in_record is True:\n",
    "                        msg = 'found start tag, but already in a record!\\nline: {} {}'.format(i, line.strip())\n",
    "                        raise IOError(msg)\n",
    "                    in_record = True\n",
    "                    _add_tag_line(tag, line, tag_match.end(), record)\n",
    "                    prev_tag = tag\n",
    "                    continue\n",
    "\n",
    "                if in_record is False:\n",
    "                    raise IOError('start/end tag mismatch!\\nline: {} {}'.format(i, line.strip()))\n",
    "\n",
    "                if tag in TAG_KEY_MAPPING:\n",
    "                    _add_tag_line(tag, line, tag_match.end(), record)\n",
    "                    prev_tag = tag\n",
    "                    continue\n",
    "                                    \n",
    "                # multi-value tag line happens to start with a tag-compliant string\n",
    "                if prev_tag in MULTI_TAGS:\n",
    "                    _add_tag_line(prev_tag, line, 0, record)\n",
    "                    continue\n",
    "                \n",
    "                # no idea what this is, but might as well save it\n",
    "                print('unknown tag: tag={}, line={} \"{}\"'.format(tag, i, line.strip()))\n",
    "                record[tag] = line[tag_match.end():].strip()\n",
    "                \n",
    "            elif prev_tag in MULTI_TAGS:\n",
    "                _add_tag_line(prev_tag, line, 0, record)\n",
    "                continue\n",
    "                \n",
    "            # single-value tag split across multiple lines, ugh\n",
    "            elif line.startswith('   '):\n",
    "                key = TAG_KEY_MAPPING[prev_tag]\n",
    "                record[key] += ' ' + line.strip()\n",
    "\n",
    "            else:\n",
    "                print('bad line: prev_tag={}, line={} \"{}\"'.format(prev_tag, i, line.strip()))\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import io\n",
    "import re\n",
    "\n",
    "from dateutil.parser import parse as parse_date\n",
    "\n",
    "\n",
    "KEY_MAP = {\n",
    "    'A1': 'primary_authors',  # special: Lastname, Firstname, Suffix\n",
    "    'A2': 'secondary_authors',  # special: Lastname, Firstname, Suffix\n",
    "    'A3': 'tertiary_authors',  # special: Lastname, Firstname, Suffix\n",
    "    'A4': 'subsidiary_authors',  # special: Lastname, Firstname, Suffix\n",
    "    'AB': 'abstract',\n",
    "    'AD': 'author_addresses',\n",
    "    'AN': 'accession_number',\n",
    "    'AU': 'authors',  # special\n",
    "    'AV': 'location_in_archives',\n",
    "    'BN': 'isbn',\n",
    "    'BP': 'start_page',\n",
    "    'BT': 'bt',\n",
    "    'C1': 'custom_1',\n",
    "    'C2': 'custom_2',\n",
    "    'C3': 'custom_3',\n",
    "    'C4': 'custom_4',\n",
    "    'C5': 'custom_5',\n",
    "    'C6': 'custom_6',\n",
    "    'C7': 'custom_7',\n",
    "    'C8': 'custom_8',\n",
    "    'CA': 'caption',\n",
    "    'CN': 'call_number',\n",
    "    'CP': 'cp',\n",
    "    'CT': 'title_of_unpublished_ref',\n",
    "    'CY': 'place_published',\n",
    "    'DA': 'date',  # special: YYYY, YYYY/MM, YYYY/MM/DD/, or YYYY/MM/DD/other info\n",
    "    'DB': 'name_of_database',\n",
    "    'DE': 'author_keywords',\n",
    "    'DI': 'doi',\n",
    "    'DO': 'doi',\n",
    "    'DP': 'database_provider',\n",
    "    'DT': 'document_type',\n",
    "    'ED': 'editor',\n",
    "    'EF': 'end_file',  # ignore!\n",
    "    'EM': 'email_address',\n",
    "    'EP': 'end_page',\n",
    "    'ER': 'end_of_reference',  # special: must be empty and last tag of record\n",
    "    'ET': 'edition',\n",
    "    'FN': 'file_name',  # ignore!\n",
    "    'ID': 'reference_id',\n",
    "    'IS': 'issue_number',\n",
    "    'J1': 'journal_name_user_abbr_1',\n",
    "    'J2': 'journal_name_user_abbr_2',\n",
    "    'JA': 'journal_name_abbr',\n",
    "    'JF': 'journal_name',\n",
    "    'JO': 'journal_name',\n",
    "    'KW': 'keywords',  # special\n",
    "    'L1': 'link_to_pdf',\n",
    "    'L2': 'link_to_fulltext',\n",
    "    'L3': 'related_records',\n",
    "    'L4': 'figure',\n",
    "    'LA': 'language',\n",
    "    'LB': 'label',\n",
    "    'LK': 'link_to_website',\n",
    "    'M1': 'number',\n",
    "    'M2': 'miscellaneous_2',\n",
    "    'M3': 'type_of_work',\n",
    "    'N1': 'notes',\n",
    "    'N2': 'abstract',\n",
    "    'NV': 'number_of_volumes',\n",
    "    'OP': 'original_publication',\n",
    "    'PB': 'publisher',\n",
    "    'PD': 'publication_date',\n",
    "    'PP': 'publishing_place',\n",
    "    'PT': 'publication_type',\n",
    "    'PY': 'publication_year',  # special: YYYY\n",
    "    'RI': 'reviewed_item',\n",
    "    'RN': 'research_notes',\n",
    "    'RP': 'reprint_status',  # special: 'IN FILE', 'NOT IN FILE', or 'ON REQUEST (MM/DD/YY)'\n",
    "    'SE': 'section',\n",
    "    'SN': 'issn',\n",
    "    'SO': 'source_name',\n",
    "    'SP': 'start_page',\n",
    "    'ST': 'short_title',\n",
    "    'SU': 'supplement',\n",
    "    'T1': 'primary_title',\n",
    "    'T2': 'secondary_title',  # note: journal_title, if applicable\n",
    "    'T3': 'tertiary_title',\n",
    "    'TA': 'translated_author',\n",
    "    'TC': 'times_cited',\n",
    "    'TI': 'title',\n",
    "    'TT': 'translated_title',\n",
    "    'TY': 'type_of_reference',  # special: must be key in REFERENCE_TYPES and first tag of record\n",
    "    'U1': 'user_defined_1',\n",
    "    'U2': 'user_defined_2',\n",
    "    'U3': 'user_defined_3',\n",
    "    'U4': 'user_defined_4',\n",
    "    'U5': 'user_defined_5',\n",
    "    'UR': 'url',\n",
    "    'UT': 'unique_identifier',\n",
    "    'VL': 'volume',\n",
    "    'VO': 'published_standard_number',\n",
    "    'VR': 'version',  # ignore!\n",
    "    'Y1': 'primary_date',  # special: YYYY/\n",
    "    'Y2': 'access_date',\n",
    "}\n",
    "\n",
    "REFERENCE_TYPES_MAPPING = {\n",
    "    'ABST': 'abstract',\n",
    "    'ADVS': 'audiovisual material',\n",
    "    'AGGR': 'aggregated database',\n",
    "    'ANCIENT': 'ancient text',\n",
    "    'ART': 'art work',\n",
    "    'BILL': 'bill/resolution',\n",
    "    'BLOG': 'blog',\n",
    "    'BOOK': 'book',\n",
    "    'CASE': 'case',\n",
    "    'CHAP': 'book chapter',\n",
    "    'CHART': 'chart',\n",
    "    'CLSWK': 'classical cork',\n",
    "    'COMP': 'computer program',\n",
    "    'CONF': 'conference proceeding',\n",
    "    'CPAPER': 'conference paper',\n",
    "    'CTLG': 'catalog',\n",
    "    'DATA': 'data file',\n",
    "    'DBASE': 'online database',\n",
    "    'DICT': 'dictionary',\n",
    "    'EBOOK': 'electronic book',\n",
    "    'ECHAP': 'electronic book chapter',\n",
    "    'EDBOOK': 'edited book',\n",
    "    'EJOUR': 'electronic article',\n",
    "    'ELEC': 'web page',\n",
    "    'ENCYC': 'encyclopedia',\n",
    "    'EQUA': 'equation',\n",
    "    'FIGURE': 'figure',\n",
    "    'GEN': 'generic',\n",
    "    'GOVDOC': 'government document',\n",
    "    'GRANT': 'grant',\n",
    "    'HEAR': 'hearing',\n",
    "    'ICOMM': 'internet communication',\n",
    "    'INPR': 'in press',\n",
    "    'JFULL': 'journal (full)',\n",
    "    'JOUR': 'journal',\n",
    "    'LEGAL': 'legal rule or regulation',\n",
    "    'MANSCPT': 'manuscript',\n",
    "    'MAP': 'map',\n",
    "    'MGZN': 'magazine article',\n",
    "    'MPCT': 'motion picture',\n",
    "    'MULTI': 'online multimedia',\n",
    "    'MUSIC': 'music score',\n",
    "    'NEWS': 'newspaper',\n",
    "    'PAMP': 'pamphlet',\n",
    "    'PAT': 'patent',\n",
    "    'PCOMM': 'personal communication',\n",
    "    'RPRT': 'report',\n",
    "    'SER': 'serial publication',\n",
    "    'SLIDE': 'slide',\n",
    "    'SOUND': 'sound recording',\n",
    "    'STAND': 'standard',\n",
    "    'STAT': 'statute',\n",
    "    'THES': 'thesis/dissertation',\n",
    "    'UNBILL': 'unenacted bill/resolution',\n",
    "    'UNPB': 'unpublished work',\n",
    "    'VIDEO': 'video recording',\n",
    "}\n",
    "\n",
    "MULTI_TAGS = {'A1', 'A2', 'A3', 'A4', 'AD', 'AU', 'KW', 'N1'}\n",
    "IGNORE_TAGS = {'FN', 'VR', 'EF'}\n",
    "START_TAGS = {'TY', 'PT'}\n",
    "END_TAG = 'ER'\n",
    "\n",
    "TAGv1_RE = re.compile(r'^(?P<tag>[A-Z][A-Z0-9])(  - )')\n",
    "TAGv2_RE = re.compile(r'^(?P<tag>[A-Z][A-Z0-9])( )|^(?P<endtag>E[FR])(\\s?$)')\n",
    "\n",
    "VALUE_SANITIZERS = {\n",
    "    'DA': lambda x: parse_date(x).strftime('%Y-%m-%d'),\n",
    "    'PY': lambda x: int(x),\n",
    "    'TC': lambda x: int(x),\n",
    "    'TY': lambda x: REFERENCE_TYPES_MAPPING.get(x, x),\n",
    "    'Y1': lambda x: parse_date('-'.join(item if item else '01' for item in x[:-1].split('/'))),\n",
    "    'Y2': lambda x: min(parse_date(val) for val in x.split(' through ')),\n",
    "    }\n",
    "\n",
    "\n",
    "class RisFile(object):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path (str): RIS file to be parsed\n",
    "        key_map (dict or bool): mapping of short RIS tags to to human-readable keys;\n",
    "            if None (default), default mapping is used; if False, no mapping will be done\n",
    "        value_sanitizers (dict or bool): mapping of short RIS tags to functions\n",
    "            that sanitize their associated values; if None (default), default\n",
    "            sanitizers will be used; if False, no sanitization will be performed\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path,\n",
    "                 key_map=None,\n",
    "                 value_sanitizers=None):\n",
    "        self.path = path\n",
    "        self.key_map = (key_map if key_map is not None\n",
    "                        else KEY_MAP)\n",
    "        self.value_sanitizers = (value_sanitizers if value_sanitizers is not None\n",
    "                                 else VALUE_SANITIZERS)\n",
    "        if self.key_map:\n",
    "            self.multi_keys = {self.key_map.get(tag, tag) for tag in MULTI_TAGS}\n",
    "        else:\n",
    "            self.multi_keys = MULTI_TAGS\n",
    "        self.in_record = False\n",
    "        self.tag_re = None\n",
    "        self.prev_line_len = None\n",
    "        self.prev_tag = None\n",
    "        self.record = {}\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\"\n",
    "        Yields:\n",
    "            dict: next complete citation record\n",
    "\n",
    "        Raises:\n",
    "            IOError\n",
    "        \"\"\"\n",
    "        with io.open(self.path, mode='rt') as f:\n",
    "            for i, line in enumerate(f):\n",
    "\n",
    "                # skip empty lines\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "\n",
    "                # automatically detect regex needed for this RIS file\n",
    "                if self.tag_re is None:\n",
    "                    if TAGv1_RE.match(line):\n",
    "                        self.tag_re = TAGv1_RE\n",
    "                    elif TAGv2_RE.match(line):\n",
    "                        self.tag_re = TAGv2_RE\n",
    "                    else:\n",
    "                        msg ='tags in file {} not formatted as expected!'.format(self.path)\n",
    "                        raise IOError(msg)\n",
    "\n",
    "                tag_match = self.tag_re.match(line)\n",
    "                # lines starts with a tag\n",
    "                if tag_match:\n",
    "\n",
    "                    tag = tag_match.group('tag') or tag_match.group('endtag')\n",
    "\n",
    "                    if tag in IGNORE_TAGS:\n",
    "                        self._stash_prev_info(tag, len(line))\n",
    "                        continue\n",
    "\n",
    "                    elif tag == END_TAG:\n",
    "                        if self.in_record is False:\n",
    "                            msg = 'found end tag, but not in a record!\\nline: {} {}'.format(i, line.strip())\n",
    "                            raise IOError(msg)\n",
    "\n",
    "                        self._sort_multi_values()\n",
    "                        yield self.record  # record is complete! spit it out here\n",
    "\n",
    "                        self.in_record = False\n",
    "                        self.record = {}\n",
    "                        self._stash_prev_info(tag, len(line))\n",
    "                        continue\n",
    "\n",
    "                    elif tag in START_TAGS:\n",
    "                        if self.in_record is True:\n",
    "                            msg = 'found start tag, but already in a record!\\nline: {} {}'.format(i, line.strip())\n",
    "                            raise IOError(msg)\n",
    "                        self.in_record = True\n",
    "                        self._add_tag_line(tag, line, tag_match.end())\n",
    "                        self._stash_prev_info(tag, len(line))\n",
    "                        continue\n",
    "\n",
    "                    if self.in_record is False:\n",
    "                        msg = 'start/end tag mismatch!\\nline: {} {}'.format(i, line.strip())\n",
    "                        raise IOError(msg)\n",
    "\n",
    "                    if self.key_map and tag in self.key_map:\n",
    "                        self._add_tag_line(tag, line, tag_match.end())\n",
    "                        self._stash_prev_info(tag, len(line))\n",
    "                        continue\n",
    "\n",
    "                    # multi-value tag line happens to start with a tag-compliant string\n",
    "                    if self.prev_tag in MULTI_TAGS:\n",
    "                        self._add_tag_line(self.prev_tag, line, 0)\n",
    "                        continue\n",
    "\n",
    "                    # no idea what this is, but might as well save it\n",
    "                    print('unknown tag: tag={}, line={} \"{}\"'.format(tag, i, line.strip()))\n",
    "                    self.record[tag] = line[tag_match.end():].strip()\n",
    "                    self._stash_prev_info(tag, len(line))\n",
    "                    continue\n",
    "\n",
    "                # subsequent line belonging to a multi-value tag\n",
    "                elif self.prev_tag in MULTI_TAGS:\n",
    "                    self._add_tag_line(self.prev_tag, line, 0)\n",
    "                    continue\n",
    "\n",
    "                # single-value tag split across multiple lines, ugh\n",
    "                elif line.startswith('   ') or self.prev_line_len > 70:\n",
    "                    key = (self.key_map[self.prev_tag] if self.key_map\n",
    "                           else self.prev_tag)\n",
    "                    self.record[key] += ' ' + line.strip()\n",
    "\n",
    "                else:\n",
    "                    print('bad line: prev_tag={}, line={} \"{}\"'.format(\n",
    "                        self.prev_tag, i, line.strip()))\n",
    "\n",
    "    def _add_tag_line(self, tag, line, start_idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tag (str)\n",
    "            line (str)\n",
    "            start_idx (int)\n",
    "        \"\"\"\n",
    "        key = (self.key_map[tag] if self.key_map\n",
    "               else tag)\n",
    "        value = line[start_idx:].strip()\n",
    "        # try to sanitize value, but don't sweat failure\n",
    "        try:\n",
    "            value = self.value_sanitizers[tag](value)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        except Exception:\n",
    "            print('value sanitization error: key={}, value={}'.format(key, value))\n",
    "        # for multi-value tags, append to a list\n",
    "        if tag in MULTI_TAGS:\n",
    "            try:\n",
    "                self.record[key].append(value)\n",
    "            except KeyError:\n",
    "                self.record[key] = [value]\n",
    "        # otherwise, add key:value to record\n",
    "        else:\n",
    "            if key in self.record:\n",
    "                print('duplicate key error: key={}, value={}'.format(key, value))\n",
    "            self.record[key] = value\n",
    "\n",
    "    def _stash_prev_info(self, tag, line_len):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tag (str)\n",
    "            line_len (int)\n",
    "        \"\"\"\n",
    "        self.prev_tag = tag\n",
    "        self.prev_line_len = line_len\n",
    "\n",
    "    def _sort_multi_values(self):\n",
    "        for key in self.multi_keys:\n",
    "            try:\n",
    "                self.record[key] = tuple(sorted(self.record[key]))\n",
    "            except KeyError:\n",
    "                pass\n",
    "            except Exception:\n",
    "                print('multi-value sort error: key={}, value={}'.format(key, self.record[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = '../data/raw/citation_formats/scopus_to_ris.ris'\n",
    "# fname = '../data/raw/citation_formats/mendeley_to_ris.ris'\n",
    "# fname = '../data/raw/citation_formats/wos_to_plain_text.txt'\n",
    "records = list(RisFile(fname).parse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 'Poly (styrene-divinylbenzene) (P (St-DVB)) foams with porosity as high as 98% were prepared by the method of high internal phase emulsions (HIPEs) in one-step process. The materials exhibited superhydrophobicity and excellent oleophilicity, with the water contact angle (WCA) even exceeding 150° and oil contact angle approaching 0°. The materials fabricated with different types of Fe3O4 particles had varied hierarchical pore structures. And the adsorption capacity of the monolithic foam towards chloroform was as high as 57 g/g. Importantly, the materials soaked with oil could be regenerated effectively by means of centrifugation with oil recovery rate reaching 90%. More importantly, the monolithic PolyHIPEs (polymers obtained by the polymerization of the HIPEs) were subjected to 20 adsorption-centrifugation cycles and superior reusability was demonstrated. These features achieved with PolyHIPEs made them ideal candidates for practical oil removal applications. © 2016 Elsevier B.V.',\n",
       " 'author_addresses': ('School of Chemical Engineering, Nanjing University of Science and Technology, Nanjing, China',),\n",
       " 'authors': ('Fu, J.',\n",
       "  'Jiang, W.',\n",
       "  'Wang, T.',\n",
       "  'Zhang, N.',\n",
       "  'Zhong, S.',\n",
       "  'Zhou, X.'),\n",
       " 'doi': '10.1016/j.cej.2016.03.151',\n",
       " 'end_page': '124',\n",
       " 'issn': '13858947 (ISSN)',\n",
       " 'journal_name_user_abbr_2': 'Chem. Eng. J.',\n",
       " 'keywords': ('Adsorption',\n",
       "  'Centrifugation',\n",
       "  'Contact angle',\n",
       "  'Emulsification',\n",
       "  'Hierarchical pore structures',\n",
       "  'High internal phase emulsions',\n",
       "  'Hydrophobicity',\n",
       "  'Oil adsorption',\n",
       "  'Oil spills',\n",
       "  'Oleophilicity',\n",
       "  'Oleophilicity',\n",
       "  'PolyHIPE foam',\n",
       "  'Regeneration',\n",
       "  'Regeneration',\n",
       "  'Reusability',\n",
       "  'Styrene',\n",
       "  'Styrene-divinylbenzene',\n",
       "  'Superhydrophobicity',\n",
       "  'Superhydrophobicity',\n",
       "  'Water contact angle (WCA)',\n",
       "  'polyHIPE foams'),\n",
       " 'language': 'English',\n",
       " 'name_of_database': 'Scopus',\n",
       " 'notes': ('Barbetta, A., Cameron, N.R., Morphology and surface area of emulsion-derived (PolyHIPE) solid foams prepared with oil-phase soluble porogenic solvents: three-component surfactant system (2004) Macromolecules, 37, pp. 3202-3213;',\n",
       "  'Binks, B.P., Rodrigues, J.A., Inversion of emulsions stabilized solely by ionizable nanoparticles (2005) Angew. Chem. Int. Ed., 44, pp. 441-444;',\n",
       "  'CODEN: CMEJA',\n",
       "  'Correspondence Address: Jiang, W.; School of Chemical Engineering, Nanjing University of Science and TechnologyChina; email: superfine_jw@126.com',\n",
       "  'Export Date: 8 May 2016',\n",
       "  'Funding Details: 50972060, NSFC, Natural Science Foundation of China',\n",
       "  'Ge, X., Yang, W., Wang, J.T., Long, D.H., Ling, L.C., Qiao, W.M., Flexible carbon nanofiber sponges for highly efficient and recyclable oil absorption (2015) RSC Adv., 5, pp. 70025-70031;',\n",
       "  'Ha, H., Shanmuganathan, K., Ellison, C.J., Mechanically stable thermally crosslinked Poly(acrylic acid)/reduced graphene oxide aerogels (2015) ACS Appl. Mater. Interfaces, 7, pp. 6220-6229;',\n",
       "  'Jing, P., Fang, X.H., Yan, J.L., Guo, J., Fang, Y., Ultra-low density porous polystyrene monolith: facile preparation and superior application (2013) J. Mater. Chem. A, 1, pp. 10135-10141;',\n",
       "  'Karatum, O., Steiner, S.A., Griffin, J.S., Shi, W., Plata, D.L., Flexible, mechanically durable aerogel composites for oil capture and recovery (2015) ACS Appl. Mater. Interfaces, 8, pp. 215-224;',\n",
       "  'Khosravi, M., Azizian, S., Synthesis of a novel highly oleophilic and highly hydrophobic sponge for rapid oil spill cleanup (2015) ACS Appl. Mater. Interfaces, 7, pp. 25326-25333;',\n",
       "  'Korhonen, J.T., Kettunen, M., Ras, R.H., Ikkala, O., Hydrophobic nanocellulose aerogels as floating, sustainable, reusable, and recyclable oil absorbents (2011) ACS Appl. Mater. Interfaces, 3, pp. 1813-1816',\n",
       "  'Lee, M.W., An, S., Latthe, S.S., Lee, C., Hong, S., Yoon, S.S., Electrospun polystyrene nanofiber membrane with superhydrophobicity and superoleophilicity for selective separation of water and low viscous oil (2013) ACS Appl. Mater. Interfaces, 5, pp. 10597-10604;',\n",
       "  'Liao, C.Y., Chiou, J.Y., Lin, J.J., Temperature-dependent oil absorption of poly(oxypropylene)amine-intercalated clays for environmental remediation (2015) RSC Adv., 5, pp. 100702-100708;',\n",
       "  'Pan, J.M., Zeng, J., Cao, Q., Gao, H.P., Gen, Y.C., Peng, Y.X., Dai, X.H., Yan, Y.S., Hierarchical macro and mesoporous foams synthesized by HIPEs template and interface grafted route for simultaneous removal of λ-cyhalothrin and copper ions (2016) Chem. Eng. J., 284, pp. 1361-1372;',\n",
       "  'References: Wang, S., Peng, X.W., Zhong, L.X., Tan, J.W., Jing, S.S., Cao, X., Chen, W., Sun, R.C., An ultralight, elastic, cost-effective, and highly recyclable superabsorbent from microfibrillated cellulose fibers for oil spillage cleanup (2015) J. Mater. Chem. A, 3, pp. 8772-8781;',\n",
       "  \"Sai, H.Z., Fu, R., Xing, L., Xiang, J.H., Li, Z.Y., Li, F., Zhang, T., Surface modification of bacterial cellulose aerogels' web-like skeleton for oil/water separation (2015) ACS Appl. Mater. Interfaces, 7, pp. 7373-7381;\",\n",
       "  'Souza, R.S., Porto, P.S.S., Pintor, A.M.A., Ruphuy, G., Costa, M.F., Boaventura, R.A.R., Vilar, V.J.P., New insights on the removal of mineral oil from oil-in-water emulsions using cork by-products: effect of salt and surfactants content (2016) Chem. Eng. J., 285, pp. 709-717;',\n",
       "  'Vílchez, A., Rodriguez-Abreu, C., Menner, A., Bismarck, A., Esquena, J., Antagonistic effects between magnetite nanoparticles and hydrophobic surfactant in highly concentrated Pickering emulsions (2014) Langmuir, 30, pp. 5064-5074;',\n",
       "  'Wang, G., Zeng, Z.X., Wu, X.D., Ren, T.H., Han, J., Xue, Q.J., Three-dimensional structured sponge with high oil wettability for the clean-up of oil contaminations and separation of oil-water mixtures (2014) Polym. Chem., 5, pp. 5942-5948;',\n",
       "  'Wang, Z., Wang, D., Qian, Z.C., Guo, J., Dong, H.X., Zhao, N., Xu, J., Robust superhydrophobic bridged silsesquioxane aerogels with tunable performances and their applications (2015) ACS Appl. Mater. Interfaces, 7, pp. 2016-2024;',\n",
       "  'Wang, Z.Y., Stein, A., Morphology control of carbon, silica, and carbon/silica nanocomposites: from 3D ordered macro-/mesoporous monoliths to shaped mesoporous particles (2008) Chem. Mater., 20, pp. 1029-1040;',\n",
       "  'Yang, Y., Liu, Z.J., Huang, J., Wang, C.Y., Multifunctional, robust sponges by a simple adsorption-combustion method (2015) J. Mater. Chem. A, 3, pp. 5875-5881;',\n",
       "  'Yin, Y.J., Pan, J.M., Cao, J., Ma, Y., Pan, G.Q., Wu, R.R., Dai, X.H., Yan, Y.S., Rationally designed hybrid molecularly imprinted polymer foam for highly efficient λ-cyhalothrin recognition and uptake via twice imprinting strategy (2016) Chem. Eng. J., 286, pp. 485-496;',\n",
       "  'Yu, S.Z., Tan, H.Y., Wang, J., Liu, X., Zhou, K.B., High porosity supermacroporous polystyrene materials with excellent oil-water separation and gas permeability properties (2015) ACS Appl. Mater. Interfaces, 7, pp. 6745-6753;',\n",
       "  'Yun, S., Luo, H.J., Gao, Y.F., Ambient-pressure drying synthesis of large resorcinol-formaldehyde-reinforced silica aerogels with enhanced mechanical strength and superhydrophobicity (2014) J. Mater. Chem. A, 2, pp. 14542-14549;',\n",
       "  'Zhang, N., Jiang, W., Wang, T.H., Gu, J.J., Zhong, S.T., Zhou, S., Xie, T., Fu, J.J., Facile preparation of magnetic poly(styrene-divinylbenzene) foam and its application as an oil absorbent (2015) Ind. Eng. Chem. Res., 54, pp. 11033-11039;',\n",
       "  'Zhang, Y.L., Pan, J.M., Chen, Y., Shi, W.D., Yan, Y.S., Yu, L.B., HIPEs template: towards the synthesis of polymeric catalysts with adjustable porous structure, acid-base strength and wettability for biomass energy conversation (2016) Chem. Eng. J., 283, pp. 956-970;',\n",
       "  'Zhang, Y.L., Wei, S., Liu, F.J., Du, Y.C., Liu, S., Ji, Y.Y., Yokoi, T., Xiao, F.S., Superhydrophobic nanoporous polymers as efficient adsorbents for organic compounds (2009) Nano Today, 4, pp. 135-142;',\n",
       "  'Zhou, S., Jiang, W., Wang, T.H., Lu, Y., Highly hydrophobic, compressible, and magnetic polystyrene/Fe3O4/graphene aerogel composite for oil-water separation (2015) Ind. Eng. Chem. Res., 54, pp. 5460-5467;',\n",
       "  'Zhu, Q., Chu, Y., Wang, Z.K., Chen, N., Lin, L., Liu, F.T., Pan, Q.M., Robust superhydrophobic polyurethane sponge as a highly reusable oil-absorption material (2013) J. Mater. Chem. A, 1, pp. 5386-5393;',\n",
       "  'Zhu, Y.F., Zheng, Y., Wang, F., Wang, A.Q., Monolithic supermacroporous hydrogel prepared from high internal phase emulsions (HIPEs) for fast removal of Cu2+ and Pb2+ (2016) Chem. Eng. J., 284, pp. 422-430;'),\n",
       " 'publication_year': 2016,\n",
       " 'publisher': 'Elsevier',\n",
       " 'secondary_title': 'Chemical Engineering Journal',\n",
       " 'start_page': '117',\n",
       " 'title': 'Superhydrophobic P (St-DVB) foam prepared by the high internal phase emulsion technique for oil spill recovery',\n",
       " 'type_of_reference': 'journal',\n",
       " 'type_of_work': 'Article',\n",
       " 'url': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964327224&partnerID=40&md5=2c29d84d2ac9f9adf7a6471a85467ba4',\n",
       " 'volume': '298'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown tag: tag=ZB, line=37 \"ZB 0\"\n",
      "unknown tag: tag=Z8, line=38 \"Z8 0\"\n",
      "unknown tag: tag=ZR, line=39 \"ZR 0\"\n",
      "unknown tag: tag=ZS, line=40 \"ZS 0\"\n",
      "unknown tag: tag=Z9, line=42 \"Z9 0\"\n",
      "unknown tag: tag=EI, line=44 \"EI 1873-2119\"\n",
      "unknown tag: tag=ZB, line=85 \"ZB 0\"\n",
      "unknown tag: tag=Z8, line=86 \"Z8 0\"\n",
      "unknown tag: tag=ZR, line=87 \"ZR 0\"\n",
      "unknown tag: tag=ZS, line=88 \"ZS 0\"\n",
      "unknown tag: tag=Z9, line=90 \"Z9 0\"\n",
      "unknown tag: tag=EI, line=92 \"EI 1879-1026\"\n",
      "unknown tag: tag=PM, line=94 \"PM 26971215\"\n",
      "unknown tag: tag=ZB, line=129 \"ZB 0\"\n",
      "unknown tag: tag=Z8, line=130 \"Z8 0\"\n",
      "unknown tag: tag=ZR, line=131 \"ZR 0\"\n",
      "unknown tag: tag=ZS, line=132 \"ZS 0\"\n",
      "unknown tag: tag=Z9, line=134 \"Z9 0\"\n",
      "unknown tag: tag=EI, line=135 \"EI 1095-8630\"\n",
      "unknown tag: tag=PM, line=137 \"PM 27019358\"\n",
      "unknown tag: tag=ZB, line=166 \"ZB 0\"\n",
      "unknown tag: tag=Z8, line=167 \"Z8 0\"\n",
      "unknown tag: tag=ZR, line=168 \"ZR 0\"\n",
      "unknown tag: tag=ZS, line=169 \"ZS 0\"\n",
      "unknown tag: tag=Z9, line=171 \"Z9 0\"\n",
      "unknown tag: tag=EI, line=173 \"EI 1944-3986\"\n",
      "unknown tag: tag=ZB, line=212 \"ZB 0\"\n",
      "unknown tag: tag=Z8, line=213 \"Z8 0\"\n",
      "unknown tag: tag=ZR, line=214 \"ZR 0\"\n",
      "unknown tag: tag=ZS, line=215 \"ZS 0\"\n",
      "unknown tag: tag=Z9, line=217 \"Z9 0\"\n",
      "unknown tag: tag=EI, line=218 \"EI 1879-1298\"\n",
      "unknown tag: tag=PM, line=220 \"PM 27035386\"\n",
      "unknown tag: tag=ZB, line=259 \"ZB 0\"\n",
      "unknown tag: tag=Z8, line=260 \"Z8 0\"\n",
      "unknown tag: tag=ZR, line=261 \"ZR 0\"\n",
      "unknown tag: tag=ZS, line=262 \"ZS 0\"\n",
      "unknown tag: tag=Z9, line=264 \"Z9 0\"\n",
      "unknown tag: tag=EI, line=266 \"EI 1090-2414\"\n",
      "unknown tag: tag=PM, line=268 \"PM 26874984\"\n",
      "unknown tag: tag=ZB, line=309 \"ZB 0\"\n",
      "unknown tag: tag=Z8, line=310 \"Z8 0\"\n",
      "unknown tag: tag=ZR, line=311 \"ZR 0\"\n",
      "unknown tag: tag=ZS, line=312 \"ZS 0\"\n",
      "unknown tag: tag=Z9, line=314 \"Z9 0\"\n",
      "unknown tag: tag=EI, line=315 \"EI 1879-1298\"\n",
      "unknown tag: tag=PM, line=317 \"PM 27003367\"\n",
      "unknown tag: tag=ZB, line=354 \"ZB 0\"\n",
      "unknown tag: tag=Z8, line=355 \"Z8 0\"\n",
      "unknown tag: tag=ZR, line=356 \"ZR 0\"\n",
      "unknown tag: tag=ZS, line=357 \"ZS 0\"\n",
      "unknown tag: tag=Z9, line=359 \"Z9 0\"\n",
      "unknown tag: tag=EI, line=361 \"EI 1549-7801\"\n",
      "unknown tag: tag=PM, line=363 \"PM 25641324\"\n",
      "unknown tag: tag=ZB, line=393 \"ZB 0\"\n",
      "unknown tag: tag=Z8, line=394 \"Z8 0\"\n",
      "unknown tag: tag=ZR, line=395 \"ZR 0\"\n",
      "unknown tag: tag=ZS, line=396 \"ZS 0\"\n",
      "unknown tag: tag=Z9, line=398 \"Z9 0\"\n",
      "unknown tag: tag=ZB, line=440 \"ZB 0\"\n",
      "unknown tag: tag=Z8, line=441 \"Z8 0\"\n",
      "unknown tag: tag=ZR, line=442 \"ZR 0\"\n",
      "unknown tag: tag=ZS, line=443 \"ZS 0\"\n",
      "unknown tag: tag=Z9, line=445 \"Z9 0\"\n",
      "unknown tag: tag=EI, line=447 \"EI 1521-0529\"\n"
     ]
    }
   ],
   "source": [
    "fname = '../data/raw/citation_formats/scopus_to_ris.ris'\n",
    "fname = '../data/raw/citation_formats/mendeley_to_ris.ris'\n",
    "fname = '../data/raw/citation_formats/wos_to_plain_text.txt'\n",
    "records = parse_ris_file(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "## BibTex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import io\n",
    "import re\n",
    "\n",
    "import bibtexparser\n",
    "from bibtexparser.bparser import BibTexParser\n",
    "from bibtexparser.customization import convert_to_unicode, getnames\n",
    "\n",
    "# TODO: confirm that 'references' sanitization is correct\n",
    "\n",
    "KEY_MAP = {\n",
    "    'address': 'publisher_address',\n",
    "    'author': 'authors',\n",
    "    'keyword': 'keywords',\n",
    "    'journal': 'journal_name',\n",
    "    'month': 'publication_month',\n",
    "    'note': 'notes',\n",
    "    'number': 'issue_number',\n",
    "    'publisher': 'publisher_name',\n",
    "    'year': 'publication_year',\n",
    "}\n",
    "\n",
    "VALUE_SANITIZERS = {\n",
    "    'author': lambda x: tuple(sorted(getnames([a.strip() for a in x.replace('\\n', ' ').split(' and ')]))),\n",
    "    'keyword': lambda x: tuple(sorted(kw.strip() for kw in re.split(r',|;', x.replace('\\n', '')) if kw)),\n",
    "    'author_keywords': lambda x: tuple(sorted(kw.strip() for kw in re.split(r',|;', x.replace('\\n', '')) if kw)),\n",
    "    'month': lambda x: int(x),\n",
    "    'pages': lambda x: _sanitize_pages(x),\n",
    "    'references': lambda x: tuple(sorted(ref.strip() for ref in x.split('; ') if ref)),\n",
    "    'type': lambda x: x.lower(),\n",
    "    'year': lambda x: int(x),\n",
    "}\n",
    "\n",
    "\n",
    "def _sanitize_pages(value):\n",
    "    # hyphen, non-breaking hyphen, en dash, em dash, hyphen-minus, minus sign\n",
    "    separators = ('‐', '‑', '–', '—', '-', '−')\n",
    "    for sep in separators:\n",
    "        if sep in value:\n",
    "            pages = [i.strip().strip(sep)\n",
    "                     for i in value.split(sep)\n",
    "                     if i]\n",
    "            if len(pages) > 2:\n",
    "                print('unusual \"pages\" field value: {}', value)\n",
    "            else:\n",
    "                value = pages[0] + '--' + pages[-1]\n",
    "                break\n",
    "    return value\n",
    "\n",
    "\n",
    "def _sanitize_record(record):\n",
    "    record = {key: value\n",
    "              for key, value in record.items()\n",
    "              if value}\n",
    "    record = convert_to_unicode(record)\n",
    "    return record\n",
    "\n",
    "\n",
    "class BibTexFile(object):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        path (str): BibTex file to be parsed\n",
    "        key_map (dict or bool): mapping of default BibTex tags to to human-readable keys;\n",
    "            if None (default), default mapping is used; if False, no mapping will be done\n",
    "        value_sanitizers (dict or bool): mapping of default BibTex tags to functions\n",
    "            that sanitize their associated values; if None (default), default sanitizers\n",
    "            will be used; if False, no sanitization will be performed\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, key_map=None, value_sanitizers=None):\n",
    "        self.path = path\n",
    "        self.parser = BibTexParser()\n",
    "        self.parser.ignore_nonstandard_types = False\n",
    "        self.parser.homogenize_fields = False\n",
    "        self.parser.customization = _sanitize_record\n",
    "        self.key_map = (key_map if key_map is not None\n",
    "                        else KEY_MAP)\n",
    "        self.value_sanitizers = (value_sanitizers if value_sanitizers is not None\n",
    "                                 else VALUE_SANITIZERS)\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\"\n",
    "        Yields:\n",
    "            dict: next parsed citation record\n",
    "        \"\"\"\n",
    "        with io.open(self.path, mode='rt') as f:\n",
    "            parsed_data = bibtexparser.load(f, parser=self.parser)\n",
    "        for record in parsed_data.entries:\n",
    "            if self.value_sanitizers:\n",
    "                for key, value in record.items():\n",
    "                    try:\n",
    "                        record[key] = self.value_sanitizers[key](value)\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    except Exception:\n",
    "                        print('value sanitization error: key={}, value={}'.format(key, value))\n",
    "            if self.key_map:\n",
    "                for key, rekey in self.key_map.items():\n",
    "                    try:\n",
    "                        record[rekey] = record.pop(key)\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                \n",
    "            yield record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ENTRYTYPE': 'article',\n",
      " 'ID': 'Zhang2016117',\n",
      " 'abbrev_source_title': 'Chem. Eng. J.',\n",
      " 'abstract': 'Poly (styrene-divinylbenzene) (P (St-DVB)) foams with porosity '\n",
      "             'as high as 98% were prepared by the method of high internal '\n",
      "             'phase emulsions (HIPEs) in one-step process. The materials '\n",
      "             'exhibited superhydrophobicity and excellent oleophilicity, with '\n",
      "             'the water contact angle (WCA) even exceeding 150° and oil '\n",
      "             'contact angle approaching 0°. The materials fabricated with '\n",
      "             'different types of Fe3O4 particles had varied hierarchical pore '\n",
      "             'structures. And the adsorption capacity of the monolithic foam '\n",
      "             'towards chloroform was as high as 57 g/g. Importantly, the '\n",
      "             'materials soaked with oil could be regenerated effectively by '\n",
      "             'means of centrifugation with oil recovery rate reaching 90%. '\n",
      "             'More importantly, the monolithic PolyHIPEs (polymers obtained by '\n",
      "             'the polymerization of the HIPEs) were subjected to 20 '\n",
      "             'adsorption-centrifugation cycles and superior reusability was '\n",
      "             'demonstrated. These features achieved with PolyHIPEs made them '\n",
      "             'ideal candidates for practical oil removal applications. © 2016 '\n",
      "             'Elsevier B.V.',\n",
      " 'affiliation': 'School of Chemical Engineering, Nanjing University of Science '\n",
      "                'and Technology, Nanjing, China',\n",
      " 'author_keywords': ('Oil adsorption',\n",
      "                     'Oleophilicity',\n",
      "                     'PolyHIPE foam',\n",
      "                     'Regeneration',\n",
      "                     'Superhydrophobicity'),\n",
      " 'authors': ('Fu, J.',\n",
      "             'Jiang, W.',\n",
      "             'Wang, T.',\n",
      "             'Zhang, N.',\n",
      "             'Zhong, S.',\n",
      "             'Zhou, X.'),\n",
      " 'coden': 'CMEJA',\n",
      " 'correspondence_address1': 'Jiang, W.; School of Chemical Engineering, '\n",
      "                            'Nanjing University of Science and '\n",
      "                            'TechnologyChina; email: superfine_jw@126.com',\n",
      " 'document_type': 'Article',\n",
      " 'doi': '10.1016/j.cej.2016.03.151',\n",
      " 'funding_details': '50972060, NSFC, Natural Science Foundation of China',\n",
      " 'issn': '13858947',\n",
      " 'journal_name': 'Chemical Engineering Journal',\n",
      " 'keywords': ('Adsorption',\n",
      "              'Centrifugation',\n",
      "              'Contact angle',\n",
      "              'Emulsification',\n",
      "              'Hierarchical pore structures',\n",
      "              'High internal phase emulsions',\n",
      "              'Hydrophobicity',\n",
      "              'Oil spills',\n",
      "              'Oleophilicity',\n",
      "              'Regeneration',\n",
      "              'Reusability',\n",
      "              'Styrene',\n",
      "              'Styrene-divinylbenzene',\n",
      "              'Superhydrophobicity',\n",
      "              'Water contact angle (WCA)',\n",
      "              'polyHIPE foams'),\n",
      " 'language': 'English',\n",
      " 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964327224&partnerID=40&md5=2c29d84d2ac9f9adf7a6471a85467ba4',\n",
      " 'notes': 'cited By 0',\n",
      " 'pages': '117--124',\n",
      " 'publication_year': 2016,\n",
      " 'publisher_name': 'Elsevier',\n",
      " 'references': ('Barbetta, A., Cameron, N.R., Morphology and surface area of '\n",
      "                'emulsion-derived (PolyHIPE) solid foams prepared with '\n",
      "                'oil-phase soluble porogenic solvents: three-component '\n",
      "                'surfactant system (2004) Macromolecules, 37, pp. 3202-3213',\n",
      "                'Binks, B.P., Rodrigues, J.A., Inversion of emulsions '\n",
      "                'stabilized solely by ionizable nanoparticles (2005) Angew. '\n",
      "                'Chem. Int. Ed., 44, pp. 441-444',\n",
      "                'Ge, X., Yang, W., Wang, J.T., Long, D.H., Ling, L.C., Qiao, '\n",
      "                'W.M., Flexible carbon nanofiber sponges for highly efficient '\n",
      "                'and recyclable oil absorption (2015) RSC Adv., 5, pp. '\n",
      "                '70025-70031',\n",
      "                'Ha, H., Shanmuganathan, K., Ellison, C.J., Mechanically '\n",
      "                'stable thermally crosslinked Poly(acrylic acid)/reduced '\n",
      "                'graphene oxide aerogels (2015) ACS Appl. Mater. Interfaces, '\n",
      "                '7, pp. 6220-6229',\n",
      "                'Jing, P., Fang, X.H., Yan, J.L., Guo, J., Fang, Y., Ultra-low '\n",
      "                'density porous polystyrene monolith: facile preparation and '\n",
      "                'superior application (2013) J. Mater. Chem. A, 1, pp. '\n",
      "                '10135-10141',\n",
      "                'Karatum, O., Steiner, S.A., Griffin, J.S., Shi, W., Plata, '\n",
      "                'D.L., Flexible, mechanically durable aerogel composites for '\n",
      "                'oil capture and recovery (2015) ACS Appl. Mater. Interfaces, '\n",
      "                '8, pp. 215-224',\n",
      "                'Khosravi, M., Azizian, S., Synthesis of a novel highly '\n",
      "                'oleophilic and highly hydrophobic sponge for rapid oil spill '\n",
      "                'cleanup (2015) ACS Appl. Mater. Interfaces, 7, pp. '\n",
      "                '25326-25333',\n",
      "                'Korhonen, J.T., Kettunen, M., Ras, R.H., Ikkala, O., '\n",
      "                'Hydrophobic nanocellulose aerogels as floating, sustainable, '\n",
      "                'reusable, and recyclable oil absorbents (2011) ACS Appl. '\n",
      "                'Mater. Interfaces, 3, pp. 1813-1816',\n",
      "                'Lee, M.W., An, S., Latthe, S.S., Lee, C., Hong, S., Yoon, '\n",
      "                'S.S., Electrospun polystyrene nanofiber membrane with '\n",
      "                'superhydrophobicity and superoleophilicity for selective '\n",
      "                'separation of water and low viscous oil (2013) ACS Appl. '\n",
      "                'Mater. Interfaces, 5, pp. 10597-10604',\n",
      "                'Liao, C.Y., Chiou, J.Y., Lin, J.J., Temperature-dependent oil '\n",
      "                'absorption of poly(oxypropylene)amine-intercalated clays for '\n",
      "                'environmental remediation (2015) RSC Adv., 5, pp. '\n",
      "                '100702-100708',\n",
      "                'Pan, J.M., Zeng, J., Cao, Q., Gao, H.P., Gen, Y.C., Peng, '\n",
      "                'Y.X., Dai, X.H., Yan, Y.S., Hierarchical macro and mesoporous '\n",
      "                'foams synthesized by HIPEs template and interface grafted '\n",
      "                'route for simultaneous removal of λ-cyhalothrin and copper '\n",
      "                'ions (2016) Chem. Eng. J., 284, pp. 1361-1372',\n",
      "                'Sai, H.Z., Fu, R., Xing, L., Xiang, J.H., Li, Z.Y., Li, F., '\n",
      "                'Zhang, T., Surface modification of bacterial cellulose '\n",
      "                \"aerogels' web-like skeleton for oil/water separation (2015) \"\n",
      "                'ACS Appl. Mater. Interfaces, 7, pp. 7373-7381',\n",
      "                'Souza, R.S., Porto, P.S.S., Pintor, A.M.A., Ruphuy, G., '\n",
      "                'Costa, M.F., Boaventura, R.A.R., Vilar, V.J.P., New insights '\n",
      "                'on the removal of mineral oil from oil-in-water emulsions '\n",
      "                'using cork by-products: effect of salt and surfactants '\n",
      "                'content (2016) Chem. Eng. J., 285, pp. 709-717',\n",
      "                'Vílchez, A., Rodriguez-Abreu, C., Menner, A., Bismarck, A., '\n",
      "                'Esquena, J., Antagonistic effects between magnetite '\n",
      "                'nanoparticles and hydrophobic surfactant in highly '\n",
      "                'concentrated Pickering emulsions (2014) Langmuir, 30, pp. '\n",
      "                '5064-5074',\n",
      "                'Wang, G., Zeng, Z.X., Wu, X.D., Ren, T.H., Han, J., Xue, '\n",
      "                'Q.J., Three-dimensional structured sponge with high oil '\n",
      "                'wettability for the clean-up of oil contaminations and '\n",
      "                'separation of oil-water mixtures (2014) Polym. Chem., 5, pp. '\n",
      "                '5942-5948',\n",
      "                'Wang, S., Peng, X.W., Zhong, L.X., Tan, J.W., Jing, S.S., '\n",
      "                'Cao, X., Chen, W., Sun, R.C., An ultralight, elastic, '\n",
      "                'cost-effective, and highly recyclable superabsorbent from '\n",
      "                'microfibrillated cellulose fibers for oil spillage cleanup '\n",
      "                '(2015) J. Mater. Chem. A, 3, pp. 8772-8781',\n",
      "                'Wang, Z., Wang, D., Qian, Z.C., Guo, J., Dong, H.X., Zhao, '\n",
      "                'N., Xu, J., Robust superhydrophobic bridged silsesquioxane '\n",
      "                'aerogels with tunable performances and their applications '\n",
      "                '(2015) ACS Appl. Mater. Interfaces, 7, pp. 2016-2024',\n",
      "                'Wang, Z.Y., Stein, A., Morphology control of carbon, silica, '\n",
      "                'and carbon/silica nanocomposites: from 3D ordered '\n",
      "                'macro-/mesoporous monoliths to shaped mesoporous particles '\n",
      "                '(2008) Chem. Mater., 20, pp. 1029-1040',\n",
      "                'Yang, Y., Liu, Z.J., Huang, J., Wang, C.Y., Multifunctional, '\n",
      "                'robust sponges by a simple adsorption-combustion method '\n",
      "                '(2015) J. Mater. Chem. A, 3, pp. 5875-5881',\n",
      "                'Yin, Y.J., Pan, J.M., Cao, J., Ma, Y., Pan, G.Q., Wu, R.R., '\n",
      "                'Dai, X.H., Yan, Y.S., Rationally designed hybrid molecularly '\n",
      "                'imprinted polymer foam for highly efficient λ-cyhalothrin '\n",
      "                'recognition and uptake via twice imprinting strategy (2016) '\n",
      "                'Chem. Eng. J., 286, pp. 485-496',\n",
      "                'Yu, S.Z., Tan, H.Y., Wang, J., Liu, X., Zhou, K.B., High '\n",
      "                'porosity supermacroporous polystyrene materials with '\n",
      "                'excellent oil-water separation and gas permeability '\n",
      "                'properties (2015) ACS Appl. Mater. Interfaces, 7, pp. '\n",
      "                '6745-6753',\n",
      "                'Yun, S., Luo, H.J., Gao, Y.F., Ambient-pressure drying '\n",
      "                'synthesis of large resorcinol-formaldehyde-reinforced silica '\n",
      "                'aerogels with enhanced mechanical strength and '\n",
      "                'superhydrophobicity (2014) J. Mater. Chem. A, 2, pp. '\n",
      "                '14542-14549',\n",
      "                'Zhang, N., Jiang, W., Wang, T.H., Gu, J.J., Zhong, S.T., '\n",
      "                'Zhou, S., Xie, T., Fu, J.J., Facile preparation of magnetic '\n",
      "                'poly(styrene-divinylbenzene) foam and its application as an '\n",
      "                'oil absorbent (2015) Ind. Eng. Chem. Res., 54, pp. '\n",
      "                '11033-11039',\n",
      "                'Zhang, Y.L., Pan, J.M., Chen, Y., Shi, W.D., Yan, Y.S., Yu, '\n",
      "                'L.B., HIPEs template: towards the synthesis of polymeric '\n",
      "                'catalysts with adjustable porous structure, acid-base '\n",
      "                'strength and wettability for biomass energy conversation '\n",
      "                '(2016) Chem. Eng. J., 283, pp. 956-970',\n",
      "                'Zhang, Y.L., Wei, S., Liu, F.J., Du, Y.C., Liu, S., Ji, Y.Y., '\n",
      "                'Yokoi, T., Xiao, F.S., Superhydrophobic nanoporous polymers '\n",
      "                'as efficient adsorbents for organic compounds (2009) Nano '\n",
      "                'Today, 4, pp. 135-142',\n",
      "                'Zhou, S., Jiang, W., Wang, T.H., Lu, Y., Highly hydrophobic, '\n",
      "                'compressible, and magnetic polystyrene/Fe3O4/graphene aerogel '\n",
      "                'composite for oil-water separation (2015) Ind. Eng. Chem. '\n",
      "                'Res., 54, pp. 5460-5467',\n",
      "                'Zhu, Q., Chu, Y., Wang, Z.K., Chen, N., Lin, L., Liu, F.T., '\n",
      "                'Pan, Q.M., Robust superhydrophobic polyurethane sponge as a '\n",
      "                'highly reusable oil-absorption material (2013) J. Mater. '\n",
      "                'Chem. A, 1, pp. 5386-5393',\n",
      "                'Zhu, Y.F., Zheng, Y., Wang, F., Wang, A.Q., Monolithic '\n",
      "                'supermacroporous hydrogel prepared from high internal phase '\n",
      "                'emulsions (HIPEs) for fast removal of Cu2+ and Pb2+ (2016) '\n",
      "                'Chem. Eng. J., 284, pp. 422-430'),\n",
      " 'source': 'Scopus',\n",
      " 'title': 'Superhydrophobic P (St-DVB) foam prepared by the high internal '\n",
      "          'phase emulsion technique for oil spill recovery',\n",
      " 'volume': '298'}\n"
     ]
    }
   ],
   "source": [
    "fname = '../data/raw/citation_formats/mendeley_to_bibtek.bib'\n",
    "fname = '../data/raw/citation_formats/scopus_to_bibtek.bib'\n",
    "\n",
    "for record in BibTexFile(fname).parse():\n",
    "    pprint(record)\n",
    "    break\n",
    "#     if 'references' in record:\n",
    "#         pprint(record['references'].split('; '))\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname = '../data/raw/all_fields_Combined Search_Results_Final.txt'\n",
    "records = []\n",
    "with io.open(fname, mode='rt', encoding='utf8') as f:\n",
    "    record = {}\n",
    "    for i, line in enumerate(f):\n",
    "        if not line.strip():\n",
    "            if record:\n",
    "                records.append(record)\n",
    "            record = {}\n",
    "        else:\n",
    "            try:\n",
    "                field, value = line.split(':', 1)\n",
    "            except ValueError:\n",
    "                print(i, line)\n",
    "            record[field.strip()] = value.strip()\n",
    "            \n",
    "        if i > 1000:\n",
    "            break\n",
    "            \n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/raw/Combined Search_Results_Top_3.xls')\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
